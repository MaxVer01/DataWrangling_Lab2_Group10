"0","set.seed(123)"
"0","# Converting training and testing sets into DMatrix"
"0","XGB_dtrain <- xgb.DMatrix(data = as.matrix(XGB_train_features), label = XGB_train_labels)"
"0","XGB_dtest <- xgb.DMatrix(data = as.matrix(XGB_test_features), label = XGB_test_labels)"
"0",""
"0","# hyperparameters "
"0","params <- list(objective = ""reg:squarederror"", "
"0","               eval_metric = ""rmse"",            "
"0","               eta = 0.1,                       "
"0","               max_depth = 6,                   "
"0","               subsample = 0.8,                 "
"0","               colsample_bytree = 0.8)"
"0",""
"0","# Training"
"0","xgb_model <- xgb.train(params = params,data = XGB_dtrain,nrounds = 100, watchlist = list(train = XGB_dtrain, test = XGB_dtest),early_stopping_rounds = 10, print_every_n = 10)"
"1","[1]	train-rmse:1.062326	test-rmse:1.062402"
"1"," "
"1","
"
"1","Multiple eval metrics are present. Will use "
"1",""
"1","test_rmse"
"1",""
"1"," for early stopping.
"
"1","Will train until "
"1",""
"1","test_rmse"
"1",""
"1"," hasn't improved in "
"1",""
"1","10"
"1",""
"1"," rounds.

"
"1","[11]	train-rmse:0.642227	test-rmse:0.916295"
"1"," "
"1","
"
"1","[21]	train-rmse:0.463151	test-rmse:0.887138"
"1"," "
"1","
"
"1","[31]	train-rmse:0.332297	test-rmse:0.873729"
"1"," "
"1","
"
"1","[41]	train-rmse:0.251878	test-rmse:0.870545"
"1"," "
"1","
"
"1","Stopping. Best iteration:
"
"1",""
"1","[38]	train-rmse:0.273576	test-rmse:0.864727"
"1",""
"1","

"
"0","# Evaluating"
"0","XGB_prediction <- predict(xgb_model, XGB_dtest)"
