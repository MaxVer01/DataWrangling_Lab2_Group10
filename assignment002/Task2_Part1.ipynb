{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2, part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dbGvFHPa5EwZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3 functions for Levenshtein, Jaro and Affine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SSTbDEegFHqN"
      },
      "outputs": [],
      "source": [
        "def lsim(s, t):\n",
        "    \"\"\"\n",
        "        iterative_levenshtein(s, t) -> ldist\n",
        "        ldist is the Levenshtein distance between the strings\n",
        "        s and t.\n",
        "        For all i and j, dist[i,j] will contain the Levenshtein\n",
        "        distance between the first i characters of s and the\n",
        "        first j characters of t\n",
        "    \"\"\"\n",
        "\n",
        "    rows = len(s)+1\n",
        "    cols = len(t)+1\n",
        "    dist = [[0 for x in range(cols)] for x in range(rows)]\n",
        "\n",
        "    # source prefixes can be transformed into empty strings\n",
        "    # by deletions:\n",
        "    for i in range(1, rows):\n",
        "        dist[i][0] = i\n",
        "\n",
        "    # target prefixes can be created from an empty source string\n",
        "    # by inserting the characters\n",
        "    for i in range(1, cols):\n",
        "        dist[0][i] = i\n",
        "\n",
        "    for col in range(1, cols):\n",
        "        for row in range(1, rows):\n",
        "            if s[row-1] == t[col-1]:\n",
        "                c = 0\n",
        "            else:\n",
        "                c = 2\n",
        "            dist[row][col] = min(dist[row-1][col] + 1,       # deletion\n",
        "                                 dist[row][col-1] + 1,       # insertion\n",
        "                                 dist[row-1][col-1] + c)     # substitution\n",
        "\n",
        "    #for r in range(rows):\n",
        "     #   print(dist[r])\n",
        "\n",
        "\n",
        "    med = dist[-1][-1]\n",
        "    sim = 1 - (med/(max(len(s), len(t))))\n",
        "    return sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XUAirlFvJIMU"
      },
      "outputs": [],
      "source": [
        "def jarosim(s, t):\n",
        "    '''Jaro similarity between two strings.'''\n",
        "    s_len = len(s)\n",
        "    t_len = len(t)\n",
        "\n",
        "    if s_len == 0 and t_len == 0:\n",
        "        return 1\n",
        "\n",
        "    match_distance = (max(s_len, t_len) // 2) - 1\n",
        "\n",
        "    s_matches = [False] * s_len\n",
        "    t_matches = [False] * t_len\n",
        "\n",
        "    matches = 0\n",
        "    transpositions = 0\n",
        "\n",
        "    for i in range(s_len):\n",
        "        start = max(0, i - match_distance)\n",
        "        end = min(i + match_distance + 1, t_len)\n",
        "\n",
        "        for j in range(start, end):\n",
        "            if t_matches[j]:\n",
        "                continue\n",
        "            if s[i] != t[j]:\n",
        "                continue\n",
        "            s_matches[i] = True\n",
        "            t_matches[j] = True\n",
        "            matches += 1\n",
        "            break\n",
        "\n",
        "    if matches == 0:\n",
        "        return 0\n",
        "\n",
        "    k = 0\n",
        "    for i in range(s_len):\n",
        "        if not s_matches[i]:\n",
        "            continue\n",
        "        while not t_matches[k]:\n",
        "            k += 1\n",
        "        if s[i] != t[k]:\n",
        "            transpositions += 1\n",
        "        k += 1\n",
        "\n",
        "    return ((matches / s_len) +\n",
        "            (matches / t_len) +\n",
        "            ((matches - transpositions / 2) / matches)) / 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KbOue5OPLhEY"
      },
      "outputs": [],
      "source": [
        "def affine(s1, s2, match_score=1, mismatch_penalty=-1, gap_open_penalty=-2, gap_extend_penalty=-1):\n",
        "    # Lengths of the two strings\n",
        "    len1, len2 = len(s1), len(s2)\n",
        "\n",
        "    # Initialize score matrices\n",
        "    M = np.zeros((len1 + 1, len2 + 1))  # Main matrix for matching\n",
        "    Ix = np.zeros((len1 + 1, len2 + 1))  # Matrix for gaps in string 1\n",
        "    Iy = np.zeros((len1 + 1, len2 + 1))  # Matrix for gaps in string 2\n",
        "\n",
        "    # Fill the score matrices with initial gap penalties\n",
        "    for i in range(1, len1 + 1):\n",
        "        M[i][0] = gap_open_penalty + (i - 1) * gap_extend_penalty\n",
        "        Ix[i][0] = gap_open_penalty + (i - 1) * gap_extend_penalty\n",
        "        Iy[i][0] = -float('inf')\n",
        "\n",
        "    for j in range(1, len2 + 1):\n",
        "        M[0][j] = gap_open_penalty + (j - 1) * gap_extend_penalty\n",
        "        Iy[0][j] = gap_open_penalty + (j - 1) * gap_extend_penalty\n",
        "        Ix[0][j] = -float('inf')\n",
        "\n",
        "    # Dynamic programming to fill in the matrices\n",
        "    for i in range(1, len1 + 1):\n",
        "        for j in range(1, len2 + 1):\n",
        "            match = M[i - 1][j - 1] + (match_score if s1[i - 1] == s2[j - 1] else mismatch_penalty)\n",
        "            Ix[i][j] = max(M[i - 1][j] + gap_open_penalty, Ix[i - 1][j] + gap_extend_penalty)\n",
        "            Iy[i][j] = max(M[i][j - 1] + gap_open_penalty, Iy[i][j - 1] + gap_extend_penalty)\n",
        "            M[i][j] = max(match, Ix[i][j], Iy[i][j])\n",
        "\n",
        "    return M[len1][len2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hnbAYNogxHz4",
        "outputId": "71b9249a-5eb1-4a34-d38d-1e89b60a40ce"
      },
      "outputs": [],
      "source": [
        "acm = pd.read_csv('./ACM.csv')\n",
        "dbl = pd.read_csv('./DBLP2.csv', encoding='ISO-8859-1')\n",
        "\n",
        "acm.head()\n",
        "dbl.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to process and compare two records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jI-vXQbV66F4"
      },
      "outputs": [],
      "source": [
        "def recComp(rec1, rec2): #compares two records\n",
        "\n",
        "    #remove spaces and make first record lowercase\n",
        "    rec1_id = rec1['id']\n",
        "    rec1_title = ' '.join(str(rec1['title']).split()).lower()\n",
        "    rec1_authors = ' '.join(str(rec1['authors']).split()).lower()\n",
        "    rec1_venue = ' '.join(str(rec1['venue']).split()).lower()\n",
        "    rec1_year = rec1['year']\n",
        "\n",
        "    #removes spaces and make second record lowercase\n",
        "    rec2_id = rec2['id']\n",
        "    rec2_title = ' '.join(str(rec2['title']).split()).lower()\n",
        "    rec2_authors = ' '.join(str(rec2['authors']).split()).lower()\n",
        "    rec2_venue = ' '.join(str(rec2['venue']).split()).lower()\n",
        "    rec2_year = rec2['year']\n",
        "\n",
        "    st = lsim(rec1_title, rec2_title)\n",
        "\n",
        "    sa = jarosim(rec1_authors, rec2_authors)\n",
        "\n",
        "    sc_unscaled = affine(rec1_venue, rec2_venue)\n",
        "\n",
        "    if rec1_year == rec2_year:\n",
        "      sy = 1\n",
        "    else:\n",
        "      sy = 0\n",
        "\n",
        "\n",
        "    return rec1_id, rec2_id, st, sa, sc_unscaled, sy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparing all records from file 1 with all records from file 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0wgIe6hGJp1",
        "outputId": "6ba5ed4e-e704-44e7-da3e-5d8ae29027c3"
      },
      "outputs": [],
      "source": [
        "k=0\n",
        "rec_results = pd.DataFrame(columns = ['id1', 'id2', 'st', 'sa', 'sc_unscaled', 'sy'])\n",
        "for i in range(550):  #(acm.shape[0]): not used, too high runtime\n",
        "  for j in range(550): #(acm.shape[0]): not used, too high runtime\n",
        "    rec_results.loc[k] = recComp(acm.iloc[i], dbl.iloc[j])\n",
        "    k+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing (true) positives and precisison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS-gq6CSSpBO"
      },
      "outputs": [],
      "source": [
        "#apply [0,1] min-max scaling for the unscaled sc values\n",
        "rec_results['sc'] = (rec_results['sc_unscaled'] - rec_results['sc_unscaled'].min())/(rec_results['sc_unscaled'].max()-rec_results['sc_unscaled'].min())\n",
        "\n",
        "#compute total similarity score with wi = 1\n",
        "rec_results['score'] = (rec_results['st'] + rec_results['sa'] + rec_results['sc'] + rec_results['sa'])/4\n",
        "\n",
        "#empty dataframe with similar records\n",
        "books = pd.DataFrame()\n",
        "\n",
        "#fill dataframe with IDs of similar books and sim score\n",
        "for i in range(len(rec_results)):\n",
        "  if rec_results.iloc[i]['score'] > 0.7:\n",
        "    books.loc[i,'id2'] = rec_results.loc[i,'id1']\n",
        "    books.loc[i,'id1'] = rec_results.loc[i,'id2']\n",
        "    books.loc[i,'score'] = rec_results.loc[i,'score']\n",
        "\n",
        "#load data on \n",
        "perfect = pd.read_csv('./DBLP-ACM_perfectMapping.csv')\n",
        "\n",
        "\n",
        "# inner join on record IDs to determine true positives\n",
        "correct = books.merge(perfect, left_on=['id1', 'id2'], right_on=['idDBLP','idACM'])\n",
        "print(correct.shape[0]) # true positives\n",
        "print(books.shape[0]) # found positives\n",
        "# computing precision with true_post/all_pos\n",
        "precision = correct.shape[0]/books.shape[0]\n",
        "print(precision)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
