{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2, part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dbGvFHPa5EwZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3 functions for Levenshtein, Jaro and Affine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SSTbDEegFHqN"
      },
      "outputs": [],
      "source": [
        "def lsim(s, t):\n",
        "    \"\"\"\n",
        "        iterative_levenshtein(s, t) -> ldist\n",
        "        ldist is the Levenshtein distance between the strings\n",
        "        s and t.\n",
        "        For all i and j, dist[i,j] will contain the Levenshtein\n",
        "        distance between the first i characters of s and the\n",
        "        first j characters of t\n",
        "    \"\"\"\n",
        "\n",
        "    rows = len(s)+1\n",
        "    cols = len(t)+1\n",
        "    dist = [[0 for x in range(cols)] for x in range(rows)]\n",
        "\n",
        "    # source prefixes can be transformed into empty strings\n",
        "    # by deletions:\n",
        "    for i in range(1, rows):\n",
        "        dist[i][0] = i\n",
        "\n",
        "    # target prefixes can be created from an empty source string\n",
        "    # by inserting the characters\n",
        "    for i in range(1, cols):\n",
        "        dist[0][i] = i\n",
        "\n",
        "    for col in range(1, cols):\n",
        "        for row in range(1, rows):\n",
        "            if s[row-1] == t[col-1]:\n",
        "                c = 0\n",
        "            else:\n",
        "                c = 2\n",
        "            dist[row][col] = min(dist[row-1][col] + 1,       # deletion\n",
        "                                 dist[row][col-1] + 1,       # insertion\n",
        "                                 dist[row-1][col-1] + c)     # substitution\n",
        "\n",
        "    #for r in range(rows):\n",
        "     #   print(dist[r])\n",
        "\n",
        "\n",
        "    med = dist[-1][-1]\n",
        "    sim = 1 - (med/(max(len(s), len(t))))\n",
        "    return sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XUAirlFvJIMU"
      },
      "outputs": [],
      "source": [
        "def jarosim(s, t):\n",
        "    '''Jaro similarity between two strings.'''\n",
        "    s_len = len(s)\n",
        "    t_len = len(t)\n",
        "\n",
        "    if s_len == 0 and t_len == 0:\n",
        "        return 1\n",
        "\n",
        "    match_distance = (max(s_len, t_len) // 2) - 1\n",
        "\n",
        "    s_matches = [False] * s_len\n",
        "    t_matches = [False] * t_len\n",
        "\n",
        "    matches = 0\n",
        "    transpositions = 0\n",
        "\n",
        "    for i in range(s_len):\n",
        "        start = max(0, i - match_distance)\n",
        "        end = min(i + match_distance + 1, t_len)\n",
        "\n",
        "        for j in range(start, end):\n",
        "            if t_matches[j]:\n",
        "                continue\n",
        "            if s[i] != t[j]:\n",
        "                continue\n",
        "            s_matches[i] = True\n",
        "            t_matches[j] = True\n",
        "            matches += 1\n",
        "            break\n",
        "\n",
        "    if matches == 0:\n",
        "        return 0\n",
        "\n",
        "    k = 0\n",
        "    for i in range(s_len):\n",
        "        if not s_matches[i]:\n",
        "            continue\n",
        "        while not t_matches[k]:\n",
        "            k += 1\n",
        "        if s[i] != t[k]:\n",
        "            transpositions += 1\n",
        "        k += 1\n",
        "\n",
        "    return ((matches / s_len) +\n",
        "            (matches / t_len) +\n",
        "            ((matches - transpositions / 2) / matches)) / 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KbOue5OPLhEY"
      },
      "outputs": [],
      "source": [
        "def affine(s1, s2, match_score=1, mismatch_penalty=-1, gap_open_penalty=-2, gap_extend_penalty=-1):\n",
        "    # Lengths of the two strings\n",
        "    len1, len2 = len(s1), len(s2)\n",
        "\n",
        "    # Initialize score matrices\n",
        "    M = np.zeros((len1 + 1, len2 + 1))  # Main matrix for matching\n",
        "    Ix = np.zeros((len1 + 1, len2 + 1))  # Matrix for gaps in string 1\n",
        "    Iy = np.zeros((len1 + 1, len2 + 1))  # Matrix for gaps in string 2\n",
        "\n",
        "    # Fill the score matrices with initial gap penalties\n",
        "    for i in range(1, len1 + 1):\n",
        "        M[i][0] = gap_open_penalty + (i - 1) * gap_extend_penalty\n",
        "        Ix[i][0] = gap_open_penalty + (i - 1) * gap_extend_penalty\n",
        "        Iy[i][0] = -float('inf')\n",
        "\n",
        "    for j in range(1, len2 + 1):\n",
        "        M[0][j] = gap_open_penalty + (j - 1) * gap_extend_penalty\n",
        "        Iy[0][j] = gap_open_penalty + (j - 1) * gap_extend_penalty\n",
        "        Ix[0][j] = -float('inf')\n",
        "\n",
        "    # Dynamic programming to fill in the matrices\n",
        "    for i in range(1, len1 + 1):\n",
        "        for j in range(1, len2 + 1):\n",
        "            match = M[i - 1][j - 1] + (match_score if s1[i - 1] == s2[j - 1] else mismatch_penalty)\n",
        "            Ix[i][j] = max(M[i - 1][j] + gap_open_penalty, Ix[i - 1][j] + gap_extend_penalty)\n",
        "            Iy[i][j] = max(M[i][j - 1] + gap_open_penalty, Iy[i][j - 1] + gap_extend_penalty)\n",
        "            M[i][j] = max(match, Ix[i][j], Iy[i][j])\n",
        "\n",
        "    return M[len1][len2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hnbAYNogxHz4",
        "outputId": "71b9249a-5eb1-4a34-d38d-1e89b60a40ce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>authors</th>\n",
              "      <th>venue</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>journals/sigmod/Mackay99</td>\n",
              "      <td>Semantic Integration of Environmental Models f...</td>\n",
              "      <td>D. Scott Mackay</td>\n",
              "      <td>SIGMOD Record</td>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>conf/vldb/PoosalaI96</td>\n",
              "      <td>Estimation of Query-Result Distribution and it...</td>\n",
              "      <td>Viswanath Poosala, Yannis E. Ioannidis</td>\n",
              "      <td>VLDB</td>\n",
              "      <td>1996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>conf/vldb/PalpanasSCP02</td>\n",
              "      <td>Incremental Maintenance for Non-Distributive A...</td>\n",
              "      <td>Themistoklis Palpanas, Richard Sidle, Hamid Pi...</td>\n",
              "      <td>VLDB</td>\n",
              "      <td>2002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>conf/vldb/GardarinGT96</td>\n",
              "      <td>Cost-based Selection of Path Expression Proces...</td>\n",
              "      <td>Zhao-Hui Tang, Georges Gardarin, Jean-Robert G...</td>\n",
              "      <td>VLDB</td>\n",
              "      <td>1996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>conf/vldb/HoelS95</td>\n",
              "      <td>Benchmarking Spatial Join Operations with Spat...</td>\n",
              "      <td>Erik G. Hoel, Hanan Samet</td>\n",
              "      <td>VLDB</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id  \\\n",
              "0  journals/sigmod/Mackay99   \n",
              "1      conf/vldb/PoosalaI96   \n",
              "2   conf/vldb/PalpanasSCP02   \n",
              "3    conf/vldb/GardarinGT96   \n",
              "4         conf/vldb/HoelS95   \n",
              "\n",
              "                                               title  \\\n",
              "0  Semantic Integration of Environmental Models f...   \n",
              "1  Estimation of Query-Result Distribution and it...   \n",
              "2  Incremental Maintenance for Non-Distributive A...   \n",
              "3  Cost-based Selection of Path Expression Proces...   \n",
              "4  Benchmarking Spatial Join Operations with Spat...   \n",
              "\n",
              "                                             authors          venue  year  \n",
              "0                                    D. Scott Mackay  SIGMOD Record  1999  \n",
              "1             Viswanath Poosala, Yannis E. Ioannidis           VLDB  1996  \n",
              "2  Themistoklis Palpanas, Richard Sidle, Hamid Pi...           VLDB  2002  \n",
              "3  Zhao-Hui Tang, Georges Gardarin, Jean-Robert G...           VLDB  1996  \n",
              "4                          Erik G. Hoel, Hanan Samet           VLDB  1995  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acm = pd.read_csv('./ACM.csv')\n",
        "dbl = pd.read_csv('./DBLP2.csv', encoding='ISO-8859-1')\n",
        "\n",
        "acm.head()\n",
        "dbl.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to process and compare two records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jI-vXQbV66F4"
      },
      "outputs": [],
      "source": [
        "def recComp(rec1, rec2): #compares two records\n",
        "\n",
        "    #remove spaces and make first record lowercase\n",
        "    rec1_id = rec1['id']\n",
        "    rec1_title = ' '.join(str(rec1['title']).split()).lower()\n",
        "    rec1_authors = ' '.join(str(rec1['authors']).split()).lower()\n",
        "    rec1_venue = ' '.join(str(rec1['venue']).split()).lower()\n",
        "    rec1_year = rec1['year']\n",
        "\n",
        "    #removes spaces and make second record lowercase\n",
        "    rec2_id = rec2['id']\n",
        "    rec2_title = ' '.join(str(rec2['title']).split()).lower()\n",
        "    rec2_authors = ' '.join(str(rec2['authors']).split()).lower()\n",
        "    rec2_venue = ' '.join(str(rec2['venue']).split()).lower()\n",
        "    rec2_year = rec2['year']\n",
        "\n",
        "    st = lsim(rec1_title, rec2_title)\n",
        "\n",
        "    sa = jarosim(rec1_authors, rec2_authors)\n",
        "\n",
        "    sc_unscaled = affine(rec1_venue, rec2_venue)\n",
        "\n",
        "    if rec1_year == rec2_year:\n",
        "      sy = 1\n",
        "    else:\n",
        "      sy = 0\n",
        "\n",
        "\n",
        "    return rec1_id, rec2_id, st, sa, sc_unscaled, sy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparing all records from file 1 with all records from file 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0wgIe6hGJp1",
        "outputId": "6ba5ed4e-e704-44e7-da3e-5d8ae29027c3"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m550\u001b[39m):  \u001b[38;5;66;03m#(acm.shape[0]): not used, too high runtime\u001b[39;00m\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m550\u001b[39m): \u001b[38;5;66;03m#(acm.shape[0]): not used, too high runtime\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     rec_results\u001b[38;5;241m.\u001b[39mloc[k] \u001b[38;5;241m=\u001b[39m \u001b[43mrecComp\u001b[49m\u001b[43m(\u001b[49m\u001b[43macm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdbl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
            "Cell \u001b[0;32mIn[16], line 17\u001b[0m, in \u001b[0;36mrecComp\u001b[0;34m(rec1, rec2)\u001b[0m\n\u001b[1;32m     14\u001b[0m rec2_venue \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(rec2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvenue\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msplit())\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     15\u001b[0m rec2_year \u001b[38;5;241m=\u001b[39m rec2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m st \u001b[38;5;241m=\u001b[39m \u001b[43mlsim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec1_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrec2_title\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m sa \u001b[38;5;241m=\u001b[39m jarosim(rec1_authors, rec2_authors)\n\u001b[1;32m     21\u001b[0m sc_unscaled \u001b[38;5;241m=\u001b[39m affine(rec1_venue, rec2_venue)\n",
            "Cell \u001b[0;32mIn[12], line 31\u001b[0m, in \u001b[0;36mlsim\u001b[0;34m(s, t)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m             c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 31\u001b[0m         dist[row][col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# deletion\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdist\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# insertion\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdist\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m# substitution\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#for r in range(rows):\u001b[39;00m\n\u001b[1;32m     36\u001b[0m  \u001b[38;5;66;03m#   print(dist[r])\u001b[39;00m\n\u001b[1;32m     39\u001b[0m med \u001b[38;5;241m=\u001b[39m dist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "k=0\n",
        "rec_results = pd.DataFrame(columns = ['id1', 'id2', 'st', 'sa', 'sc_unscaled', 'sy'])\n",
        "for i in range(550):  #(acm.shape[0]): not used, too high runtime\n",
        "  for j in range(550): #(acm.shape[0]): not used, too high runtime\n",
        "    rec_results.loc[k] = recComp(acm.iloc[i], dbl.iloc[j])\n",
        "    k+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing (true) positives and precisison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "cS-gq6CSSpBO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98\n",
            "150\n",
            "0.6533333333333333\n"
          ]
        }
      ],
      "source": [
        "#apply [0,1] min-max scaling for the unscaled sc values\n",
        "rec_results['sc'] = (rec_results['sc_unscaled'] - rec_results['sc_unscaled'].min())/(rec_results['sc_unscaled'].max()-rec_results['sc_unscaled'].min())\n",
        "\n",
        "#compute total similarity score with wi = 1\n",
        "rec_results['score'] = (rec_results['st'] + rec_results['sa'] + rec_results['sc'] + rec_results['sa'])/4\n",
        "\n",
        "#empty dataframe with similar records\n",
        "books = pd.DataFrame()\n",
        "\n",
        "#fill dataframe with IDs of similar books and sim score\n",
        "for i in range(len(rec_results)):\n",
        "  if rec_results.iloc[i]['score'] > 0.7:\n",
        "    books.loc[i,'id2'] = rec_results.loc[i,'id1']\n",
        "    books.loc[i,'id1'] = rec_results.loc[i,'id2']\n",
        "    books.loc[i,'score'] = rec_results.loc[i,'score']\n",
        "\n",
        "#load data on \n",
        "perfect = pd.read_csv('./DBLP-ACM_perfectMapping.csv')\n",
        "\n",
        "\n",
        "# inner join on record IDs to determine true positives\n",
        "correct = books.merge(perfect, left_on=['id1', 'id2'], right_on=['idDBLP','idACM'])\n",
        "print(correct.shape[0]) # true positives\n",
        "print(books.shape[0]) # found positives\n",
        "# computing precision with true_post/all_pos\n",
        "precision = correct.shape[0]/books.shape[0]\n",
        "print(precision)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
